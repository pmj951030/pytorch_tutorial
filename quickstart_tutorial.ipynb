{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T13:15:19.167827Z",
     "start_time": "2022-05-04T13:15:18.610318Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T13:15:57.734476Z",
     "start_time": "2022-05-04T13:15:55.691056Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader ## 데이터 가져오기\n",
    "from torchvision import datasets ## 예시데이터 가져오기\n",
    "from torchvision.transforms import ToTensor ## 텐서 형태로 바꾸는거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch는 데이터 세트를 포함하는 TorchText , TorchVision 및 TorchAudio 와 같은 도메인별 라이브러리를 제공합니다 . 이 튜토리얼에서는 TorchVision 데이터 세트를 사용할 것입니다.  \n",
    "\n",
    "\n",
    "이 torchvision.datasets모듈에는 CIFAR, COCO( 전체 목록은 여기Dataset ) 와 같은 많은 실제 비전 데이터에 대한 개체가 포함되어 있습니다 . 이 튜토리얼에서는 FashionMNIST 데이터 세트를 사용합니다. 모든 TorchVision 에는 샘플 과 레이블을 각각 수정하기 위한 두 개의 인수가 포함 됩니다.Datasettransformtarget_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T13:19:31.048898Z",
     "start_time": "2022-05-04T13:19:23.090617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47033484e684eb98c1e3c8275fcf733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9d374788c54903b2bc6a38c24ac86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45dfbb0285df4877a1d01a07f1dc0897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2381ebf1d2b548578ade2b8ded938d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "## FashionMNIST 데이터 가져오기\n",
    "training_data = datasets.FashionMNIST( \n",
    "    root=\"data\", ## 다운 경로\n",
    "    train=True, ## train 데이터\n",
    "    download=True, ## 다운\n",
    "    transform=ToTensor(), ## 데이터 형태 tensor로\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False, ## 테스트 데이터\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T13:20:49.948021Z",
     "start_time": "2022-05-04T13:20:49.938052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset에 인수로 전달 합니다 DataLoader. 이것은 우리의 데이터 세트에 대해 iterable을 래핑하고 자동 일괄 처리, 샘플링, 셔플링 및 다중 프로세스 데이터 로드를 지원합니다. 여기에서 배치 크기를 64로 정의합니다. 즉, 반복 가능한 데이터 로더의 각 요소는 64개의 기능 및 레이블 배치를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T13:20:55.659993Z",
     "start_time": "2022-05-04T13:20:55.608777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 ## 배치 사이즈\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성\n",
    "PyTorch에서 신경망을 정의하기 위해 nn.Module에서 상속하는 클래스를 만듭니다 . 함수 에서 네트워크 계층을 정의하고 \\__init__함수에서 데이터가 네트워크를 통과하는 방법을 지정합니다 forward. 신경망에서 작업을 가속화하기 위해 가능한 경우 이를 GPU로 이동합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T13:24:45.617051Z",
     "start_time": "2022-05-04T13:24:45.596024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" ## cpu로할건지 gpu로 할건지\n",
    "print(f\"Using {device} device\") ## 현재 cpu인지 gpu 인지 확인 (노트북이라 cpu)\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(), ## 활성화 함수 (0 보다 커야 반응)\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 매개변수 최적화\n",
    "모델을 훈련시키려면 손실 함수 와 옵티마이저가 필요합니다 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T13:25:55.612191Z",
     "start_time": "2022-05-04T13:25:55.604215Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss() ## 분류문제 이므로 crossentropyloss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) ## 경사하강법, 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단일 훈련 루프에서 모델은 훈련 데이터 세트에 대한 예측을 수행하고(배치로 제공됨) 예측 오류를 역전파하여 모델의 매개변수를 조정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T13:27:08.214457Z",
     "start_time": "2022-05-04T13:27:08.200494Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device) ## model 실행?을 cpu에서 했으므로 데이터도 cpu상으로 해야함 cpu, gpu 따로 안된다고함\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() ## 역전파\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 테스트 데이터 세트에 대해 모델의 성능을 확인하여 학습 중인지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T13:29:02.508866Z",
     "start_time": "2022-05-04T13:29:02.486928Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 프로세스는 여러 반복( epoch )에 걸쳐 수행됩니다. 각 에포크 동안 모델은 더 나은 예측을 위해 매개변수를 학습합니다. 각 에포크에서 모델의 정확도와 손실을 인쇄합니다. 우리는 매 에포크마다 정확도가 증가하고 손실이 감소하는 것을 보고 싶습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T13:30:23.439817Z",
     "start_time": "2022-05-04T13:29:12.473659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.313918  [    0/60000]\n",
      "loss: 2.298969  [ 6400/60000]\n",
      "loss: 2.277369  [12800/60000]\n",
      "loss: 2.272837  [19200/60000]\n",
      "loss: 2.260240  [25600/60000]\n",
      "loss: 2.225194  [32000/60000]\n",
      "loss: 2.231590  [38400/60000]\n",
      "loss: 2.194631  [44800/60000]\n",
      "loss: 2.195538  [51200/60000]\n",
      "loss: 2.171096  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 41.3%, Avg loss: 2.157212 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.172703  [    0/60000]\n",
      "loss: 2.153878  [ 6400/60000]\n",
      "loss: 2.092723  [12800/60000]\n",
      "loss: 2.113528  [19200/60000]\n",
      "loss: 2.069128  [25600/60000]\n",
      "loss: 2.001689  [32000/60000]\n",
      "loss: 2.032920  [38400/60000]\n",
      "loss: 1.946570  [44800/60000]\n",
      "loss: 1.959259  [51200/60000]\n",
      "loss: 1.898784  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 1.879931 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.913480  [    0/60000]\n",
      "loss: 1.877866  [ 6400/60000]\n",
      "loss: 1.750464  [12800/60000]\n",
      "loss: 1.808801  [19200/60000]\n",
      "loss: 1.715421  [25600/60000]\n",
      "loss: 1.647677  [32000/60000]\n",
      "loss: 1.683537  [38400/60000]\n",
      "loss: 1.574108  [44800/60000]\n",
      "loss: 1.613611  [51200/60000]\n",
      "loss: 1.521760  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 1.520556 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.580334  [    0/60000]\n",
      "loss: 1.547753  [ 6400/60000]\n",
      "loss: 1.390467  [12800/60000]\n",
      "loss: 1.484448  [19200/60000]\n",
      "loss: 1.381057  [25600/60000]\n",
      "loss: 1.350441  [32000/60000]\n",
      "loss: 1.377965  [38400/60000]\n",
      "loss: 1.293645  [44800/60000]\n",
      "loss: 1.338028  [51200/60000]\n",
      "loss: 1.248131  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 1.260570 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.325900  [    0/60000]\n",
      "loss: 1.311825  [ 6400/60000]\n",
      "loss: 1.143620  [12800/60000]\n",
      "loss: 1.266515  [19200/60000]\n",
      "loss: 1.152357  [25600/60000]\n",
      "loss: 1.153709  [32000/60000]\n",
      "loss: 1.183390  [38400/60000]\n",
      "loss: 1.115134  [44800/60000]\n",
      "loss: 1.159218  [51200/60000]\n",
      "loss: 1.081717  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 1.093161 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장\n",
    "모델을 저장하는 일반적인 방법은 내부 상태 사전(모델 매개변수 포함)을 직렬화하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T13:30:55.985100Z",
     "start_time": "2022-05-04T13:30:55.965155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 로드 중\n",
    "모델을 로드하는 프로세스에는 모델 구조를 다시 만들고 상태 사전을 로드하는 작업이 포함됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T13:30:57.764778Z",
     "start_time": "2022-05-04T13:30:57.741841Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이 모델을 사용하여 예측할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T13:31:26.318632Z",
     "start_time": "2022-05-04T13:31:26.295699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Dress\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
